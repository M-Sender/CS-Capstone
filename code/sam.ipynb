{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here for live site!](https://m-sender.github.io/notupyet)\n",
    "<center><h1>Music Trends During the Pandemic</h1></center>\n",
    "<center><b>Sam Broth and Max Sender</b></center>\n",
    "<center>-------------------------------------------------------</center>\n",
    "\n",
    "<center>1. Introduction</center>\n",
    "<center>2. Data: Extraction, Transform and Load</center>\n",
    "<center>3. Exploratory Data Analysis</center>\n",
    "<center>4. Visualization</center>\n",
    "<center>5. What it all means?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>1. Introduction</h1></center>\n",
    "\n",
    "# Goals\n",
    "\n",
    "# Our Data\n",
    "\n",
    "# Questions and Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from functools import partial\n",
    "import requests\n",
    "import json\n",
    "from lyricsgenius import Genius\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import sqlite3\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>2. Extraction, Transform and Load </h1></center>\n",
    "\n",
    "We can do like 2.a, 2.b, etc for tidying and organizing and merging and such with explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tracks_df = pd.read_csv(\"../datasets/tracks.csv\")\n",
    "artist_df = pd.read_csv(\"../datasets/artists.csv\")\n",
    "final_df = pd.read_csv(\"../datasets/Final database.csv\")\n",
    "full_df = pd.read_csv(\"../datasets/Database to calculate popularity.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying up our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks_df.sort_values('popularity', ascending=False)[tracks_df['popularity']>50].head()\n",
    "tracks_df\n",
    "#find the most popular tracks\n",
    "tracks_df.sort_values('popularity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health_df = pd.read_csv(\"../datasets/mentalHealth_searchTrend.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['date'] = pd.to_datetime(full_df['date'],dayfirst=True)\n",
    "full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.iloc[305933].uri\n",
    "full_df['id'] = [x.split('/')[-1] if type(x)==str else float('nan') for x in full_df.uri.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(pd.to_datetime,yearfirst=True)\n",
    "working_df = full_df[(full_df['date']>=f('01/01/2020')) & (full_df['date']<=f('06/30/2020'))].sort_values('date',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[(tracks_df['name']=='Tongue Tied') & (tracks_df['artists']==\"['Grouplove']\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holder_df = working_df.merge(tracks_df,on='id',how='inner')\n",
    "holder_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>3. Exploratory Data Analysis</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break down our data analysis into 3 parts:\n",
    "* (3.1) Analysis and Representation of Provided Metrics\n",
    "* (3.2) NLP sentiment analysis of the lyrics per genre\n",
    "* (3.3) Meshing the data together and pursuing further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>3.1: Analysis and Representation of Provided Metrics</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for plotting graphs and metrics\n",
    "def createMetricComparison(metricName): #change to zscore // streams per week (look)\n",
    "    fig, ax = plt.subplots(1,2,figsize=(25,12), sharey=True, sharex=False)\n",
    "    title = metricName + ' Before and After Pandemic Starts'\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "\n",
    "    \n",
    "\n",
    "    #holder_df[holder_df['country']== 'USA'].plot.scatter(x='date',y='danceability', c='liveness',ax=ax)\n",
    "    #group by dates, get scores for each in terms of danceability and apply weight, then sum, them plot\n",
    "    #convert zscore = \n",
    "    holder_df[metricName] = (holder_df[metricName] - holder_df[metricName].mean())/holder_df[metricName].std()\n",
    "    pre_pandemic = holder_df[(holder_df['date']<=f('03/10/2020'))] #  & (holder_df['date'].dt.day % 7 == 0)\n",
    "    pandemic = holder_df[(holder_df['date']>f('03/10/2020'))] # & (holder_df['date'].dt.day % 7 == 0)\n",
    "    pre_pandemic = pre_pandemic[pre_pandemic['country']=='USA']\n",
    "    pandemic = pandemic[pandemic['country']=='USA']\n",
    "  \n",
    "    \n",
    "    \n",
    "    pp_groupby = pre_pandemic.groupby('date')[metricName].mean() \n",
    "    dp_groupby = pandemic.groupby('date')[metricName].mean() \n",
    "    #get zscore\n",
    "    '''pp_groupby_z = (pp_groupby - pp_groupby.mean())/pp_groupby.std()\n",
    "    dp_groupby_z = (dp_groupby - dp_groupby.mean())/dp_groupby.std()'''\n",
    "    std_pre = pp_groupby.std()\n",
    "    pp_groupby.plot(ax=ax[0],title='Before Pandemic',ylabel=metricName, xlabel='Date')\n",
    "    dp_groupby.plot(ax=ax[1],title='After Pandemic Begins', xlabel='Date',ylabel=metricName)\n",
    "    #plt.axhline(y=pp_groupby.mean(), color='r', linestyle='-')\n",
    "    ax[0].hlines(y=pp_groupby.mean(), xmin=\"01-01-2020\", xmax=\"03-10-2020\", linewidth=2, color='r')\n",
    "    ax[0].hlines(y=pp_groupby.mean()+std_pre, xmin=\"01-01-2020\", xmax=\"03-10-2020\", linewidth=2, color='y',linestyle='--')\n",
    "    ax[0].hlines(y=pp_groupby.mean()-std_pre, xmin=\"01-01-2020\", xmax=\"03-10-2020\", linewidth=2, color='y',linestyle='--')\n",
    "    \n",
    "    #plt.axhline( y=dp_groupby.mean(), color='r', linestyle='-')\n",
    "    ax[1].hlines(y=pp_groupby.mean()+std_pre, xmin=\"03-11-2020\", xmax=\"06-30-2020\", linewidth=2, color='y',linestyle='--')\n",
    "    ax[1].hlines(y=pp_groupby.mean()-std_pre, xmin=\"03-11-2020\", xmax=\"06-30-2020\", linewidth=2, color='y',linestyle='--')\n",
    "    \n",
    "    ax[1].hlines(y=dp_groupby.mean(), xmin=\"03-11-2020\", xmax=\"06-30-2020\", linewidth=2, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createMetricComparison('danceability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = ['danceability','energy','loudness','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature','key','mode']\n",
    "for metric in metric_list:\n",
    "    createMetricComparison(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>3.2: NLP sentiment analysis of the lyrics per genre</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using genius API we obtained lyrics and stored in sqlite file for use, (see lyricgrabber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('lyric_store.db')\n",
    "\n",
    "lyric_df = pd.read_sql_query(\"SELECT * FROM lyrics\", conn)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df.rename(columns={'song':'title'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pandemic_lyr = working_df[(working_df['date']<=f('03/10/2020')) & (holder_df['date'].dt.day % 7 == 0)]\n",
    "pandemic_lyr = working_df[(working_df['date']>f('03/10/2020')) & (holder_df['date'].dt.day % 7 == 0)]\n",
    "full_lyr = pd.merge(pre_pandemic_lyr,pandemic_lyr,how='outer')\n",
    "full_lyr = pd.merge(full_lyr,lyric_df,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_lyr.head())\n",
    "display(lyric_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the lyric_df, we can generate a list of words and their frequencies for each song.\n",
    "#We should make new df with song and then list as well as each weeks collective for analysis\n",
    "lyric_df['words'] = None\n",
    "word_stops = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for index, row in lyric_df.iterrows():\n",
    "        song_word_hold = {}\n",
    "        words = row['lyric'].split()\n",
    "        for word in words:\n",
    "            if word.lower() in song_word_hold:\n",
    "                song_word_hold[word.lower()] += 1\n",
    "            else:\n",
    "                song_word_hold[word.lower()] = 1\n",
    "        lyric_df.loc[index]['words'] = list(song_word_hold.items())\n",
    "lyric_df.head()\n",
    "#for each song, get the lyrics, split into words, and count the frequency of each word.\n",
    "#each song from the top 100 will be analyzed per week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for per week/day analysis\n",
    "lyric_df.groupby('date').lyric.apply(' '.join).reset_index()\n",
    "#for each song, get the lyrics, split into words, and count the frequency of each word.\n",
    "#each song from the top 100 will be analyzed per week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>3.3: Meshing the data together and pursuing further analysis</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>4. Visualization</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>5. What it all means?</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
